standard-dropout0.1:
  experiment:
    model_file: examples/output/{EXP}.mod
    hyp_file: examples/output/{EXP}.hyp
    out_file: examples/output/{EXP}.out
    err_file: examples/output/{EXP}.err
    eval_metrics: bleu
  train: !SimpleTrainingRegimen
    run_for_epochs: 20
    glob:
      default_layer_dim: 512
      dropout: 0.1
    restart_trainer: True
    trainer: !AdamTrainer
      alpha: 0.0002
    lr_decay: 0.5
    dev_metrics: bleu
    corpus_parser: !BilingualCorpusParser
      src_reader: !PlainTextReader {}
      trg_reader: !PlainTextReader {}
      training_corpus: !BilingualTrainingCorpus
        train_src: examples/data/train.ja
        train_trg: examples/data/train.en
        dev_src: examples/data/dev.ja
        dev_trg: examples/data/dev.en
    model: !DefaultTranslator
      src_embedder: !PretrainedSimpleWordEmbedder
        filename: examples/data/wiki.ja.vec.small
        emb_dim: 300
      encoder: !BiLSTMSeqTransducer
        layers: 1
      attender: !MlpAttender
        hidden_dim: 512
        state_dim: 512
        input_dim: 512
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 512
      decoder: !MlpSoftmaxDecoder
        layers: 1
        mlp_hidden_dim: 512
        bridge: !CopyBridge {}
  inference: !SimpleInference
    src_file: examples/data/test.ja
  evaluate:
    ref_file: examples/data/test.en
