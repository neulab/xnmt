# XNMT offers a very flexible way of multi-task training by specifying multiple
# models and using the !Ref mechanism for weight sharing, as demonstrated
# in this config file.
# The possible multi-task training strategies can be looked up in
# xnmt/training_regimen.py and include same-batch, alternating-batch, and serial
# strategies.
exp1-multi_task: !Experiment
  exp_global: !ExpGlobal
    model_file: examples/output/{EXP}.mod
    log_file: examples/output/{EXP}.log
    default_layer_dim: 64
  train: !SameBatchMultiTaskTrainingRegimen
    trainer: !AdamTrainer {}
    n_task_steps: [2,1]
    tasks:
    - !SimpleTrainingTask # first task is the main task: it will control early stopping, learning rate schedule, model checkpoints, ..
      name: first_task
      run_for_epochs: 6
      batcher: !SrcBatcher
        batch_size: 6
      src_file: examples/data/head.ja
      trg_file: examples/data/head.en
      model: !DefaultTranslator
        _xnmt_id: first_task_model
        src_reader: !PlainTextReader
          vocab: !Vocab
            _xnmt_id: src_vocab
            vocab_file: examples/data/head.ja.vocab
        trg_reader: !PlainTextReader
          vocab: !Vocab
            _xnmt_id: trg_vocab
            vocab_file: examples/data/head.en.vocab
        src_embedder: !SimpleWordEmbedder
          emb_dim: 64
          vocab: !Ref {name: src_vocab}
        encoder: !BiLSTMSeqTransducer # the encoder shares parameters between tasks
          _xnmt_id: first_task_encoder
          layers: 1
        attender: !MlpAttender
          state_dim: 64
          hidden_dim: 64
          input_dim: 64
        trg_embedder: !SimpleWordEmbedder
          emb_dim: 64
          vocab: !Ref {name: trg_vocab}
        decoder: !AutoRegressiveDecoder
          rnn: !UniLSTMSeqTransducer
            layers: 1
            hidden_dim: 64
          bridge: !CopyBridge {}
          scorer: !Softmax
            vocab: !Ref {name: trg_vocab}
      dev_tasks:
        - !AccuracyEvalTask
          model: !Ref { name: first_task_model }
          src_file: &first_task_dev_src examples/data/head.ja  # value-sharing between first task dev and final eval
          ref_file: &first_task_dev_trg examples/data/head.en  # value-sharing between first task dev and final eval
          hyp_file: examples/output/{EXP}.first_dev_hyp
          eval_metrics: bleu # tasks can specify different dev_metrics
    - !SimpleTrainingTask
      name: second_task
      batcher: !SrcBatcher
        batch_size: 6
      src_file: examples/data/head.ja
      trg_file: examples/data/head.en
      model: !DefaultTranslator
        _xnmt_id: second_task_model
        src_reader: !PlainTextReader
          vocab: !Ref {name: src_vocab}
        trg_reader: !PlainTextReader
          vocab: !Ref {name: trg_vocab}
        src_embedder: !SimpleWordEmbedder
          emb_dim: 64
          vocab: !Ref {name: src_vocab}
        encoder: !Ref { name: first_task_encoder }
        attender: !MlpAttender
          state_dim: 64
          hidden_dim: 64
          input_dim: 64
        trg_embedder: !SimpleWordEmbedder
          emb_dim: 64
          vocab: !Ref {name: trg_vocab}
        decoder: !AutoRegressiveDecoder
          bridge: !CopyBridge {}
          scorer: !Softmax
            vocab: !Ref {name: trg_vocab}
      dev_tasks:
        - !AccuracyEvalTask
          model: !Ref { name: second_task_model }
          src_file: examples/data/head.ja
          ref_file: examples/data/head.en
          hyp_file: examples/output/{EXP}.second_dev_hyp
          eval_metrics: gleu # tasks can specify different dev_metrics
  evaluate:
    - !AccuracyEvalTask
      model: !Ref { name: first_task_model }
      eval_metrics: bleu
      src_file: *first_task_dev_src
      ref_file: *first_task_dev_trg
      hyp_file: examples/output/{EXP}.test_hyp

exp2-finetune-model: !LoadSerialized
  filename: examples/output/exp1-multi_task.mod
