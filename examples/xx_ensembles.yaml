# A standard setup, specifying model architecture, training parameters, 
# and evaluation of the trained model
ensemble: !Experiment # 'standard' is the name given to the experiment
  # global parameters shared throughout the experiment
  exp_global: !ExpGlobal
    # {EXP_DIR} is a placeholder for the directory in which the config file lies.
    # {EXP} is a placeholder for the experiment name (here: 'standard')
    model_file: '{EXP_DIR}/models/{EXP}.mod'
    log_file: '{EXP_DIR}/logs/{EXP}.log'
    default_layer_dim: 512
    dropout: 0.3
  # model architecture
  model: !EnsembleTranslator
    # src_reader and trg_reader must logically be the same for all members of an
    # ensemble, and some task functions expect them to be attributes of a
    # 'model', so we define them here
    src_reader: !PlainTextReader
      _xnmt_id: my_src_reader
      vocab: !Vocab {vocab_file: examples/data/head.ja.vocab}
    trg_reader: !PlainTextReader
      _xnmt_id: my_trg_reader
      vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
    models:
      - !DefaultTranslator
        # TODO: unfortunately, we have to explicitly reference the readers in the
        #       submodels right now, as the constructor expects it
        src_reader: !Ref {name: my_src_reader}
        trg_reader: !Ref {name: my_trg_reader}
        encoder: !BiLSTMSeqTransducer
          _xnmt_id: first_model_encoder
          layers: 1
        attender: !MlpAttender
          hidden_dim: 512
          state_dim: 512
          input_dim: 512
        trg_embedder: !SimpleWordEmbedder
          emb_dim: 512
        decoder: !MlpSoftmaxDecoder
          rnn_layer: !UniLSTMSeqTransducer
            layers: 1
          mlp_layer: !MLP
            hidden_dim: 512
          bridge: !CopyBridge {}
      - !DefaultTranslator
        src_reader: !Ref {name: my_src_reader}
        trg_reader: !Ref {name: my_trg_reader}
        # this model has a different number of layers with different dimensions
        encoder: !BiLSTMSeqTransducer
          layers: 3
        trg_embedder: !SimpleWordEmbedder
          emb_dim: 64
        decoder: !MlpSoftmaxDecoder
          rnn_layer: !UniLSTMSeqTransducer
            layers: 3
          mlp_layer: !MLP
            hidden_dim: 64
          bridge: !CopyBridge {}
      - !DefaultTranslator
        src_reader: !Ref {name: my_src_reader}
        trg_reader: !Ref {name: my_trg_reader}
        # let's share the first model's encoder with this one, and use some
        # different components compared to the other models
        encoder: !Ref {name: first_model_encoder}
        trg_embedder: !DenseWordEmbedder
          _xnmt_id: third_model_embedder
          emb_dim: 32
        decoder: !MlpSoftmaxDecoder
          rnn_layer: !UniLSTMSeqTransducer
            layers: 1
          mlp_layer: !MLP
            hidden_dim: 32
            output_projector: !Ref {name: third_model_embedder}
          bridge: !LinearBridge
            dec_layers: 1
  # training parameters
  train: !SimpleTrainingRegimen
    trainer: !AdamTrainer
      alpha: 0.001
    run_for_epochs: 2
    src_file: examples/data/head.ja
    trg_file: examples/data/head.en
    dev_tasks:
      - !LossEvalTask
        src_file: examples/data/head.ja
        ref_file: examples/data/head.en
  # final evaluation
  evaluate:
    - !AccuracyEvalTask
      eval_metrics: bleu,wer
      src_file: examples/data/head.ja
      ref_file: examples/data/head.en
      hyp_file: examples/output/{EXP}.test_hyp
