standard-preproc: !Experiment
  xnmt_global: !XnmtGlobal
    model_file: examples/output/{EXP}.mod
    out_file: examples/output/{EXP}.out
    err_file: examples/output/{EXP}.err
  preproc:
    overwrite: False
    preproc_specs:
    - type: tokenize
      in_files:
      - examples/data/train.ja
      - examples/data/train.en
      - examples/data/dev.ja
      - examples/data/dev.en
      - examples/data/test.ja
      - examples/data/test.en
      out_files:
      - examples/preproc/train.tok.ja
      - examples/preproc/train.tok.en
      - examples/preproc/dev.tok.ja
      - examples/preproc/dev.tok.en
      - examples/preproc/test.tok.ja
      - examples/preproc/test.tok.en
      specs:
      - filenum: all
        tokenizers:
        - !SentencepieceTokenizer
          # Replace <SENTENCEPIECE_SRC_PATH> with src/ directory of sentencepiece repository
          # The spm_* executables should be located at <SENTENCEPIECE_SRC_PATH>
          path: <SENTENCEPIECE_SRC_PATH>
          train_files:
           - examples/data/train.ja
           - examples/data/train.en
          vocab_size: 8000
          model_type: unigram
          model_prefix: examples/preproc/sentpiece
    - type: normalize
      in_files:
      - examples/preproc/train.tok.ja
      - examples/preproc/train.tok.en
      - examples/preproc/dev.tok.ja
      - examples/preproc/dev.tok.en
      - examples/preproc/test.tok.ja
      - examples/preproc/test.tok.en
      - examples/data/dev.en
      - examples/data/test.en
      out_files:
      - examples/preproc/train.tok.norm.ja
      - examples/preproc/train.tok.norm.en
      - examples/preproc/dev.tok.norm.ja
      - examples/preproc/dev.tok.norm.en
      - examples/preproc/test.tok.norm.ja
      - examples/preproc/test.tok.norm.en
      - examples/preproc/dev.norm.en
      - examples/preproc/test.norm.en
      specs:
      - filenum: all
        spec:
        - type: lower
    - type: filter
      in_files:
      - examples/preproc/train.tok.norm.ja
      - examples/preproc/train.tok.norm.en
      out_files:
      - examples/preproc/train.tok.norm.filter.ja
      - examples/preproc/train.tok.norm.filter.en
      specs:
      - type: length
        min: 1
        max: 60
    - type: vocab
      in_files:
      - examples/preproc/train.tok.norm.ja
      - examples/preproc/train.tok.norm.en
      out_files:
      - examples/preproc/train.vocab.ja
      - examples/preproc/train.vocab.en
      specs:
      - filenum: all
        spec:
        - type: freq
          min_freq: 2
  model: !DefaultTranslator
    src_reader: !PlainTextReader
      vocab: !Vocab
        vocab_file: examples/preproc/train.vocab.ja
    trg_reader: !PlainTextReader
      vocab: !Vocab
        vocab_file: examples/preproc/train.vocab.en
    src_embedder: !SimpleWordEmbedder
      emb_dim: 512
    encoder: !BiLSTMSeqTransducer
      layers: 1
    attender: !MlpAttender
      hidden_dim: 512
      state_dim: 512
      input_dim: 512
    trg_embedder: !SimpleWordEmbedder
      emb_dim: 512
    decoder: !MlpSoftmaxDecoder
      layers: 1
      mlp_hidden_dim: 512
      bridge: !NoBridge {}
    inference: !SimpleInference
      post_process: join-piece
  train: !SimpleTrainingRegimen
    run_for_epochs: 20
    src_file: examples/preproc/dev.tok.norm.ja
    trg_file: examples/preproc/dev.tok.norm.en
    dev_tasks:
      - !AccuracyEvalTask
        eval_metrics: bleu
        src_file: examples/preproc/dev.tok.norm.ja
        ref_file: examples/preproc/dev.norm.en
        hyp_file: examples/output/{EXP}.dev_hyp
      - !LossEvalTask
        src_file: examples/preproc/dev.tok.norm.ja
        ref_file: examples/preproc/dev.tok.norm.en
  evaluate:
  - !AccuracyEvalTask
    eval_metrics: bleu
    src_file: examples/preproc/test.tok.norm.ja
    ref_file: examples/preproc/test.norm.en
    hyp_file: examples/output/{EXP}.test_hyp
