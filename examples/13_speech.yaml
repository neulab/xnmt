# This config file demonstrates how to specify a speech recognition model
# using the Listen-Attend-Spell architecture: https://arxiv.org/pdf/1508.01211.pdf
# Compared to the conventional attentional model, we remove input embeddings,
# instead directly read in a feature vector the pyramidal LSTM reduces length of
# the input sequence by a factor of 2 per layer (except for the first layer).
# Output units should be characters according to the paper.
speech: !Experiment
  exp_global: !ExpGlobal
    save_num_checkpoints: 2
    default_layer_dim: 32
    dropout: 0.4
  preproc: !PreprocRunner
    overwrite: False
    tasks:
    - !PreprocExtract
      in_files:
      - examples/data/LDC94S13A.yaml
      out_files:
      - examples/data/LDC94S13A.h5
      specs: !MelFiltExtractor {}
  model: !DefaultTranslator
    src_embedder: !NoopEmbedder
      emb_dim: 40
    encoder: !PyramidalLSTMSeqTransducer
      layers: 3
      downsampling_method: concat
      reduce_factor: 2
      input_dim: 40
      hidden_dim: 64
    attender: !MlpAttender
      state_dim: 64
      hidden_dim: 64
      input_dim: 64
    trg_embedder: !SimpleWordEmbedder
      emb_dim: 64
    decoder: !AutoRegressiveDecoder
      rnn: !UniLSTMSeqTransducer
        layers: 1
      transform: !AuxNonLinear
        output_dim: 64
      bridge: !CopyBridge {}
    src_reader: !H5Reader
      transpose: True
    trg_reader: !PlainTextReader
      vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
  train: !SimpleTrainingRegimen
    run_for_epochs: 2
    batcher: !SrcBatcher
      pad_src_to_multiple: 4
      batch_size: 3
      src_pad_token: ~
    trainer: !AdamTrainer {}
    src_file: examples/data/LDC94S13A.h5
    trg_file: examples/data/LDC94S13A.char
    dev_tasks:
      - !LossEvalTask
        src_file: examples/data/LDC94S13A.h5
        ref_file: examples/data/LDC94S13A.char
      - !AccuracyEvalTask
        eval_metrics: cer,wer
        src_file: examples/data/LDC94S13A.h5
        ref_file: examples/data/LDC94S13A.char
        hyp_file: examples/output/{EXP}.dev_hyp
        inference: !AutoRegressiveInference
          post_process: join-char
          batcher: !InOrderBatcher
            _xnmt_id: inference_batcher
            pad_src_to_multiple: 4
            batch_size: 1
            src_pad_token: ~
  evaluate:
    - !AccuracyEvalTask
      eval_metrics: cer,wer
      src_file: examples/data/LDC94S13A.h5
      ref_file: examples/data/LDC94S13A.words
      hyp_file: examples/output/{EXP}.test_hyp
      inference: !AutoRegressiveInference
        post_process: join-char
        batcher: !Ref { name: inference_batcher }
