reload:
  experiment:
    model_file: test/tmp/output/<EXP>.mod
    hyp_file: test/tmp/output/<EXP>.hyp
    out_file: test/tmp/output/<EXP>.out
    err_file: test/tmp/output/<EXP>.err
    run_for_epochs: 10
    eval_metrics: cer,wer
  train: !XnmtTrainer
    reload_command: >-
      python script/code/reload_example.py
      --initial-dir examples/data/
      --tmp-basedir test/tmp/reload-tmp
      --target-dir test/tmp/reload
    src_format: contvec
    corpus_parser: !BilingualCorpusParser
      lazy_read: True
      src_reader: !ContVecReader
        transpose: True
      trg_reader: !PlainTextReader
        vocab: !Vocab
          vocab_file: examples/data/head.en.vocab
      training_corpus: !BilingualTrainingCorpus
        train_src: test/tmp/reload/synth.contvec.npz
        train_trg: test/tmp/reload/synth.char
        dev_src: test/tmp/reload/synth.contvec.npz
        dev_trg: test/tmp/reload/synth.char
    model: !DefaultTranslator
      src_embedder: !NoopEmbedder
        emb_dim: 240
      encoder: !PyramidalLSTMSeqTransducer
        layers: 1
        downsampling_method: skip
        input_dim: 240
        hidden_dim: 64
      attender: !StandardAttender
        state_dim: 64
        hidden_dim: 64
        input_dim: 64
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 64
      decoder: !MlpSoftmaxDecoder
        layers: 1
        mlp_hidden_dim: 64
        bridge: !CopyBridge {}
  decode:
    src_file: test/tmp/reload/synth.contvec.npz
  evaluate:
    ref_file: test/tmp/reload/synth.char

