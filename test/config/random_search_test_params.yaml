# Demonstrates random search over search parameters
defaults: &defaults !Experiment
  exp_global: !ExpGlobal
    default_layer_dim: 64
  model: !DefaultTranslator
    src_reader: !PlainTextReader
      vocab: !Vocab {vocab_file: examples/data/head.ja.vocab}
    trg_reader: !PlainTextReader
      vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
    src_embedder: !SimpleWordEmbedder
      emb_dim: 64
    encoder: !BiLSTMSeqTransducer
      layers: 1
      input_dim: 64
    attender: !MlpAttender
      state_dim: 64
      hidden_dim: 64
      input_dim: 64
    trg_embedder: !SimpleWordEmbedder
      emb_dim: 64
    decoder: !MlpSoftmaxDecoder
      rnn_layer: !UniLSTMSeqTransducer
        layers: 1
      mlp_layer: !MLP
        hidden_dim: 64
      bridge: !CopyBridge {}
    inference: !SimpleInference
      search_strategy: !BeamSearch
        beam_size: !RandomParam
          values: [1,2,3,4,5]
        len_norm: !PolynomialNormalization
          apply_during_search: true
          m: !RandomParam
            values: [0.2,0.5,0.7,1.0,1.3]
  train: null
  evaluate:
    - !AccuracyEvalTask
      eval_metrics: bleu,wer
      src_file: examples/data/head.ja
      ref_file: examples/data/head.en
      hyp_file: test/tmp/{EXP}.test_hyp

# Here we instantiate 3 experiments, for each the random params are drawn independently
exp1: *defaults
exp2: *defaults
exp3: *defaults
