# This demonstrates using a sequence classifier model that takes a sequence as input and outputs a single class label.
classifier: !Experiment
  model: !SequenceClassifier
    src_reader: !PlainTextReader
      vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
    trg_reader: !IDReader {}
    src_embedder: !SimpleWordEmbedder
      emb_dim: 512
    encoder: !BiLSTMSeqTransducer
      layers: 1
    scorer: !Softmax
      vocab_size: 10
  train: !SimpleTrainingRegimen
    batcher: !SrcBatcher
      batch_size: 32
    trainer: !AdamTrainer
      alpha: 0.001
    run_for_epochs: 2
    src_file: examples/data/head.en
    trg_file: examples/data/head.smallids
    dev_tasks:
      - !LossEvalTask
        src_file: examples/data/head.en
        ref_file: examples/data/head.smallids
      - !AccuracyEvalTask
        eval_metrics: accuracy
        src_file: examples/data/head.en
        ref_file: examples/data/head.smallids
        hyp_file: test/tmp/{EXP}.test_hyp
        inference: !IndependentOutputInference
          batcher: !InOrderBatcher
            batch_size: 2
