defaults: !Experiment
  kwargs: &defaults
    exp_global: !ExpGlobal
      default_layer_dim: 64
      dropout: 0.5
      weight_noise: 0.1
    train: !SimpleTrainingRegimen &defaults_train
      run_for_epochs: 2
      src_file: examples/data/head.ja
      trg_file: examples/data/head.en
      dev_tasks:
        - !LossEvalTask
          src_file: examples/data/head.ja
          ref_file: examples/data/head.en
    evaluate:
      - !AccuracyEvalTask
        eval_metrics: bleu,wer
        src_file: examples/data/head.ja
        ref_file: examples/data/head.en
        hyp_file: test/tmp/{EXP}.test_hyp


exp1-lstm-encoder: !Experiment
  kwargs:
    << : *defaults
    model: !DefaultTranslator
      src_reader: !PlainTextReader
        vocab: !Vocab {vocab_file: examples/data/head.ja.vocab}
      trg_reader: !PlainTextReader
        vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
      src_embedder: !SimpleWordEmbedder
        emb_dim: 64
        word_dropout: 0.3
      encoder: !BiLSTMSeqTransducer
        layers: 2
        input_dim: 64
      attender: !MlpAttender
        state_dim: 64
        hidden_dim: 64
        input_dim: 64
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 64
        word_dropout: 0.3
      decoder: !AutoRegressiveDecoder
        rnn: !UniLSTMSeqTransducer
          layers: 1
        input_feeding: True
        bridge: !CopyBridge {}
      inference: !AutoRegressiveInference {}

exp2-residual-encoder: !Experiment
  kwargs:
    << : *defaults
    model: !DefaultTranslator
      src_reader: !PlainTextReader
        vocab: !Vocab {vocab_file: examples/data/head.ja.vocab}
      trg_reader: !PlainTextReader
        vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
      src_embedder: !SimpleWordEmbedder
        emb_dim: 64
      encoder: !ModularSeqTransducer
        input_dim: 64
        modules:
        - !ResidualSeqTransducer
          child: !BiLSTMSeqTransducer
            input_dim: 64
        - !BiLSTMSeqTransducer
          input_dim: 64
      attender: !MlpAttender
        state_dim: 64
        hidden_dim: 64
        input_dim: 64
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 64
      decoder: !AutoRegressiveDecoder
        rnn: !UniLSTMSeqTransducer
          layers: 2
        bridge: !CopyBridge {}
      inference: !AutoRegressiveInference {}
exp3-pyramidal-encoder: !Experiment
  kwargs:
    << : *defaults
    train: !SimpleTrainingRegimen
      << : *defaults_train
      batcher: !SrcBatcher &batcher3
        _xnmt_id: batcher3
        batch_size: 5
        pad_src_to_multiple: 4
    model: !DefaultTranslator
      src_reader: !PlainTextReader
        vocab: !Vocab {vocab_file: examples/data/head.ja.vocab}
      trg_reader: !PlainTextReader
        vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
      src_embedder: !SimpleWordEmbedder
        emb_dim: 64
      encoder: !PyramidalLSTMSeqTransducer
        layers: 3
        input_dim: 64
        hidden_dim: 64
      attender: !MlpAttender
        state_dim: 64
        hidden_dim: 64
        input_dim: 64
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 64
      decoder: !AutoRegressiveDecoder
        rnn: !UniLSTMSeqTransducer
          layers: 2
        input_feeding: True
        bridge: !CopyBridge {}
      inference: !AutoRegressiveInference
        batcher: !InOrderBatcher
          batch_size: 1
          pad_src_to_multiple: 4
exp4-modular-encoder: !Experiment
  kwargs:
    << : *defaults
    train: !SimpleTrainingRegimen
      << : *defaults_train
      batcher: !SrcBatcher &batcher4
        _xnmt_id: batcher4
        batch_size: 5
        pad_src_to_multiple: 4
    model: !DefaultTranslator
      src_reader: !PlainTextReader
        vocab: !Vocab {vocab_file: examples/data/head.ja.vocab}
      trg_reader: !PlainTextReader
        vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
      src_embedder: !SimpleWordEmbedder
        emb_dim: 64
      encoder: !ModularSeqTransducer
        modules:
        - !BiLSTMSeqTransducer
          input_dim: 64
          hidden_dim: 64
          layers: 1
          dropout: 0.1
        - !PyramidalLSTMSeqTransducer
          input_dim: 64
          hidden_dim: 64
          layers: 2
      attender: !MlpAttender
        state_dim: 64
        hidden_dim: 64
        input_dim: 64
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 64
      decoder: !AutoRegressiveDecoder
        rnn: !UniLSTMSeqTransducer
          layers: 3
        input_feeding: True
        bridge: !CopyBridge {}
      inference: !AutoRegressiveInference
        batcher: !InOrderBatcher
          batch_size: 1
          pad_src_to_multiple: 4

